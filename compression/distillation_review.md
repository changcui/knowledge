​	Besides improving the performance of the person re-identification pipeline
in terms of computational cost at test time, we also aim at maximising the
performance of a small network to be as accurate as possible.
​	As discussed in [12], the simplest way to transfer the knowledge is to use
the output of the teacher network as **soft targets** for the student network,
additionally to the **hard targets** provided by the groundtruth. However,
when the **soft targets have high entropy**, they provide **more information** to
learn from them. Then, a network that is very confident about its prediction,
will generate a probability distribution similar to a Dirac delta function, in
which the correct class has a very high probability and the rest of classes
have almost zero probability, having a very low entropy and consequently
providing less information than a less confident network. This is shown
graphically in Fig. 2. The intuition behind the fact that a distribution with
high entropy helps the distillation, is that by learning from the probabilities
assigned to incorrect classes, the student network is learning how the teacher
model generalises.
​	Therefore, the authors propose to increase the entropy of the probability
distribution generated by the teacher model, i.e. the output of the softmax
layer, so that when the student network uses that output to learn from it,
it can provide more information. In order to maximize the entropy, they
propose to increase the temperature of this distribution.

[Optimizing Speed/Accuracy Trade-Off for Person
Re-identification via Knowledge Distillation](https://arxiv.org/pdf/1812.02937.pdf)